---
# Documentation: https://wowchemy.com/docs/managing-content/

title: A New Index for Information Gain in the Bayesian Framework‚Åé
subtitle: ''
summary: ''
authors:
- Prem Jagadeesan
- Karthik Raman
- Arun K. Tangirala
tags:
- '"Approximate Bayesian Computation (ABC)"'
- '"Bhattacharyya Coefficient"'
- '"Information Gain"'
- '"Model selection"'
- '"Model Sloppiness"'
- '"Practical Identifiability"'
categories: []
date: '2020-01-01'
lastmod: 2020-10-31T20:34:33+05:30
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2020-10-31T15:04:33.358520Z'
publication_types:
- '2'
abstract: In data-driven dynamical modeling, precise estimation of the parameters
  of large models from limited data has been considered a challenging task. The precision
  of the parameter estimates is highly dependent upon the information contained in
  the data; Loss of practical identifiability and sloppiness in the model structure
  are major challenges in estimating parameters precisely and closely related to the
  information contained in the data. Therefore, quantifying information is an important
  step in data-driven modeling. Quantifying information is a well-studied problem
  in the frequentist approach, where Fisher Information is one of the widely used
  metrics. However, Fisher Information computed via maximum likelihood estimation
  cannot accommodate any known prior knowledge about the parameters. Prior knowledge
  of the parameters along with informative experiments will improve the precision
  of the estimates. Bayesian estimation accommodates prior information in the form
  of a p.d.f. There has been very little work in the literature for quantifying information
  in the Bayesian framework. In this work, we introduce a new method for estimating
  information gain in the Bayesian framework using what is known as the Bhattacharyya
  coefficient. It is seen that the bounds of the coefficient have an insightful interpretation
  naturally in terms of information gain on the parameter of interest. We also demonstrate
  using case studies that the information gain of each parameter is an indication
  of loss of practical identifiability and sloppy parameters. It is also shown that
  the proposed information gain can be used as a model selection tool in black-box
  identification.
publication: '*IFAC-PapersOnLine*'
doi: 10.1016/j.ifacol.2020.06.106
---
